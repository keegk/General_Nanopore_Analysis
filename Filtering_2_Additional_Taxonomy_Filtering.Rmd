---
title: "Step 2 filtering - additional filtering of BLASTn results
output: html_notebook

Below is an example with concatenated BLASTn text files of 24 barcodes (one concatenated file per barcode) from a Nanopore run (SQK-RBK114. The BLASTn files have previously been assigned full taxonomy in the R notebook 'Filtering_1_Assigning_Taxonomy.Rmd'
---

```{r setup}

#install.packages(tidyverse)

library(tidyverse)


```



Load in the taxa file for all barcodes (previously filtered in assigning_taxonomy.Rmd to remove duplicate reads with distinct function. No unclassified reads or misassigned barcodes are in this file either. 19/03/2025)
```{r}
load("gm3_distinct_clean") 

```



```{r}


gm3_stringent_2025_clean <- gm3_merged_with_taxa %>%
                mutate(proportional_gap_number = gaps/alignment.length) %>%# 7.11.24 adding this as i think gaps set at less than 5 is too harsh for longer reads 
                mutate(proportional_mismatch_number = mismatches/alignment.length) %>% # 7.11.24 adding this as i think gaps set at less than 5 is too harsh for longer reads 
 # filter(gaps <= 5) %>% #and across the whole dataset, filter out any reads that have gaps more than 5 and
               #filter(mismatches <= 200) %>% #mismatches more than 200
              
              filter(proportional_mismatch_number <= 0.1) %>%
              filter(proportional_gap_number <= 0.1) %>% #here i am saying that there can be up to and including 10% gaps in the alignment 
                          #l ine 428-433 is general filtering of the entire dataset
               # filter(mismatches <= 200) %>%
                mutate(alignment.prop = alignment.length/query.length)%>%
                filter(alignment.prop >= 0.25) %>%
                filter(query.length >= 500)%>%
                filter(subject.length >= 100)#%>% #line 428-433 is general filtering of the entire dataset
  

 gm3_stringent_cleanJune2025 <- gm3_stringent_2025_clean %>% 
               group_by (query.acc, subject.tax.ids) %>% # code from line 436-451 written with nick as the weighted approach 25.10.24
            
               mutate(evalue_nonzero = ifelse(evalue == 0, 1, evalue), 
                      relative_evalue = ifelse(evalue == 0, 1, min(evalue_nonzero)/evalue_nonzero)) %>%
              mutate(relative_alignment_length = alignment.length/max(alignment.length)) %>%
              mutate(alignment_count = n()) %>% #taxon alignment count within a read 
              
              ungroup() %>%
              group_by(query.acc) %>%
             filter(!species.y == "NA") %>% #ADDING THIS june 2025 to remove reads with no taxonomic info
              mutate(relative_count = alignment_count/n()) %>% #proportion of read alignments to a taxon
               mutate(weight_score = relative_evalue*relative_alignment_length*(percent.identity/100)) %>%
             filter(weight_score == max(weight_score)) %>%
              filter(relative_count == max(relative_count)) %>%
              slice_sample(n=1) %>%
              ungroup()

save(gm3_stringent_cleanJune2025, file = "gm3_stringent_cleanJune2025") #saving the file for quick reloading later on

load("gm3_stringent_cleanJune2025")

#time took = 5 mins, ran fine the first time
#this now has the exact same number of reads as the first time i filtered, but now we have no NA in the taxa info, so the reads retained are the ones with all taxa info. Use this filtering as final version. 19/06/2025
```